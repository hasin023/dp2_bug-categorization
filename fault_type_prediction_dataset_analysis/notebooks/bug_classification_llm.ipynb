{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# BUG CLASSIFICATION USING LLMS - COMPLETE IMPLEMENTATION\n",
        "# ============================================================================\n",
        "# This notebook implements automatic bug classification using LLMs\n",
        "# with context from our manually annotated survey dataset\n",
        "# ============================================================================"
      ],
      "metadata": {
        "id": "JJuZGPeRZ4jo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SETUP AND INSTALLATION"
      ],
      "metadata": {
        "id": "JtYN0KxFaDmz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ikPGs2srYeRR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import openai\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from enum import Enum\n",
        "import time\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import warnings\n",
        "import requests\n",
        "import base64\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai instructor pydantic langchain scikit-learn pandas numpy seaborn matplotlib requests beautifulsoup4 PyGithub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4iBzoOWZ6xH",
        "outputId": "b97d97c1-a688-4959-8e7a-92dd17f06413"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Collecting instructor\n",
            "  Downloading instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.7)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Collecting PyGithub\n",
            "  Downloading pygithub-2.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from instructor) (3.12.15)\n",
            "Collecting diskcache>=5.6.3 (from instructor)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from instructor) (0.17.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from instructor) (3.1.6)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from instructor) (2.33.2)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.7.0 in /usr/local/lib/python3.12/dist-packages (from instructor) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from instructor) (8.5.0)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from instructor) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (2.10.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor) (1.20.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor) (3.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pynacl>=1.4.0->PyGithub) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.7.0->instructor) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.7.0->instructor) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.9.0->instructor) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.9.0->instructor) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub) (2.22)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.7.0->instructor) (0.1.2)\n",
            "Downloading instructor-1.10.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygithub-2.7.0-py3-none-any.whl (416 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.5/416.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diskcache, pynacl, PyGithub, instructor\n",
            "Successfully installed PyGithub-2.7.0 diskcache-5.6.3 instructor-1.10.0 pynacl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import instructor\n",
        "from pydantic import BaseModel, Field\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "LLM_MODEL = 'gpt-4o-mini'\n",
        "# Set up API keys\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "except:\n",
        "    OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")\n",
        "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "    os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n",
        "except:\n",
        "    print(\"Note: GitHub token not found. Some rate limits may apply.\")\n",
        "    GITHUB_TOKEN = None"
      ],
      "metadata": {
        "id": "31lODLUyZ82f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATA MODELS AND TYPES"
      ],
      "metadata": {
        "id": "u4_fpRhnagPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BugCategory(str, Enum):\n",
        "    \"\"\"Bug category enumeration for structured classification\"\"\"\n",
        "    SEMANTIC = \"semantic\"\n",
        "    MEMORY = \"memory\"\n",
        "    CONCURRENCY = \"concurrency\"\n",
        "    OTHER = \"other\"\n",
        "\n",
        "class BugClassification(BaseModel):\n",
        "    \"\"\"Structured output model for bug classification\"\"\"\n",
        "    category: BugCategory = Field(description=\"Primary bug category\")\n",
        "    confidence: float = Field(\n",
        "        description=\"Confidence score between 0.0 and 1.0\",\n",
        "        ge=0.0, le=1.0\n",
        "    )\n",
        "    reasoning: str = Field(description=\"Explanation for the classification decision\")\n",
        "    secondary_categories: List[BugCategory] = Field(\n",
        "        default=[],\n",
        "        description=\"Additional relevant categories if applicable\"\n",
        "    )\n",
        "\n",
        "class EnhancedIssueData(BaseModel):\n",
        "    \"\"\"Enhanced model for GitHub issue data with comprehensive content\"\"\"\n",
        "    url: str\n",
        "    title: str\n",
        "    body: str\n",
        "    repository: str\n",
        "    issue_number: str\n",
        "    labels: List[str] = Field(default=[])\n",
        "    comments: List[str] = Field(default=[])\n",
        "    code_snippets: List[str] = Field(default=[])\n",
        "    error_traces: List[str] = Field(default=[])\n",
        "    language: Optional[str] = None\n",
        "    created_at: Optional[str] = None\n",
        "    state: Optional[str] = None"
      ],
      "metadata": {
        "id": "_UX187ioahd6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GITHUB ISSUE FETCHER"
      ],
      "metadata": {
        "id": "wKQXJmYlc4OE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedGitHubIssueFetcher:\n",
        "    \"\"\"Enhanced GitHub issue fetcher using both API and web scraping\"\"\"\n",
        "\n",
        "    def __init__(self, github_token: Optional[str] = None):\n",
        "        self.github_token = github_token\n",
        "        self.github_client = Github(github_token) if github_token else Github()\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Bug-Classification-Tool/1.0',\n",
        "            'Accept': 'application/vnd.github.v3+json'\n",
        "        })\n",
        "        if github_token:\n",
        "            self.session.headers.update({'Authorization': f'token {github_token}'})\n",
        "\n",
        "    def extract_repo_info(self, url: str) -> Tuple[str, str, str]:\n",
        "        \"\"\"Extract repository owner, name, and issue number from URL\"\"\"\n",
        "        parts = url.replace('https://github.com/', '').split('/')\n",
        "        if len(parts) >= 4 and parts[2] == 'issues':\n",
        "            owner = parts[0]\n",
        "            repo = parts[1]\n",
        "            issue_num = parts[3]\n",
        "            return owner, repo, issue_num\n",
        "        raise ValueError(f\"Invalid GitHub issue URL: {url}\")\n",
        "\n",
        "    def extract_code_snippets(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract code snippets from markdown text\"\"\"\n",
        "        code_blocks = re.findall(r'```[\\w]*\\n(.*?)\\n```', text, re.DOTALL)\n",
        "        inline_code = re.findall(r'`([^`\\n]+)`', text)\n",
        "        return code_blocks + inline_code\n",
        "\n",
        "    def extract_error_traces(self, text: str) -> List[str]:\n",
        "        \"\"\"Extract error traces and stack traces from text\"\"\"\n",
        "        # Common error patterns\n",
        "        patterns = [\n",
        "            r'(.*?Error:.*?)(?=\\n\\n|\\n[A-Z]|\\Z)',\n",
        "            r'(.*?Exception:.*?)(?=\\n\\n|\\n[A-Z]|\\Z)',\n",
        "            r'(Traceback.*?)(?=\\n\\n|\\Z)',\n",
        "            r'(.*?failed.*?)(?=\\n\\n|\\n[A-Z]|\\Z)',\n",
        "            r'(.*?crash.*?)(?=\\n\\n|\\n[A-Z]|\\Z)'\n",
        "        ]\n",
        "\n",
        "        traces = []\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)\n",
        "            traces.extend(matches)\n",
        "\n",
        "        return [trace.strip() for trace in traces if len(trace.strip()) > 20]\n",
        "\n",
        "    def detect_programming_language(self, repo_name: str, content: str) -> Optional[str]:\n",
        "        \"\"\"Detect programming language from repository name and content\"\"\"\n",
        "        # Language hints from repo name\n",
        "        lang_indicators = {\n",
        "            'java': ['spring', 'maven', 'gradle', 'hibernate'],\n",
        "            'python': ['django', 'flask', 'python', 'py'],\n",
        "            'javascript': ['js', 'node', 'react', 'vue', 'angular'],\n",
        "            'cpp': ['cpp', 'c++', 'cmake'],\n",
        "            'c': ['linux', 'kernel', 'gcc'],\n",
        "            'go': ['go', 'golang'],\n",
        "            'rust': ['rust', 'cargo'],\n",
        "            'php': ['php', 'laravel', 'symfony']\n",
        "        }\n",
        "\n",
        "        repo_lower = repo_name.lower()\n",
        "        for lang, indicators in lang_indicators.items():\n",
        "            if any(indicator in repo_lower for indicator in indicators):\n",
        "                return lang\n",
        "\n",
        "        # Language hints from content\n",
        "        content_lower = content.lower()\n",
        "        if 'java' in content_lower or '.java' in content_lower:\n",
        "            return 'java'\n",
        "        elif 'python' in content_lower or '.py' in content_lower:\n",
        "            return 'python'\n",
        "        elif 'javascript' in content_lower or '.js' in content_lower:\n",
        "            return 'javascript'\n",
        "\n",
        "        return None\n",
        "\n",
        "    def fetch_issue_via_api(self, owner: str, repo: str, issue_num: str) -> Optional[EnhancedIssueData]:\n",
        "        \"\"\"Fetch issue using GitHub API (more reliable and comprehensive)\"\"\"\n",
        "        try:\n",
        "            repository = self.github_client.get_repo(f\"{owner}/{repo}\")\n",
        "            issue = repository.get_issue(int(issue_num))\n",
        "\n",
        "            # Get comments\n",
        "            comments = []\n",
        "            for comment in issue.get_comments():\n",
        "                if comment.body and len(comment.body.strip()) > 10:\n",
        "                    comments.append(comment.body)\n",
        "\n",
        "            # Combine title and body for analysis\n",
        "            full_content = f\"{issue.title}\\n\\n{issue.body or ''}\"\n",
        "            for comment in comments[:5]:  # Limit to first 5 comments\n",
        "                full_content += f\"\\n\\n{comment}\"\n",
        "\n",
        "            # Extract structured information\n",
        "            code_snippets = self.extract_code_snippets(full_content)\n",
        "            error_traces = self.extract_error_traces(full_content)\n",
        "            language = self.detect_programming_language(repository.name, full_content)\n",
        "\n",
        "            return EnhancedIssueData(\n",
        "                url=issue.html_url,\n",
        "                title=issue.title,\n",
        "                body=issue.body or \"\",\n",
        "                repository=f\"{owner}/{repo}\",\n",
        "                issue_number=str(issue.number),\n",
        "                labels=[label.name for label in issue.labels],\n",
        "                comments=comments[:10],  # Limit comments\n",
        "                code_snippets=code_snippets[:5],  # Limit code snippets\n",
        "                error_traces=error_traces[:3],  # Limit error traces\n",
        "                language=language,\n",
        "                created_at=str(issue.created_at) if issue.created_at else None,\n",
        "                state=issue.state\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"API fetch failed for {owner}/{repo}/issues/{issue_num}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def fetch_issue_via_web(self, url: str) -> Optional[EnhancedIssueData]:\n",
        "        \"\"\"Fallback web scraping method\"\"\"\n",
        "        try:\n",
        "            owner, repo, issue_num = self.extract_repo_info(url)\n",
        "\n",
        "            response = self.session.get(url)\n",
        "            if response.status_code != 200:\n",
        "                return None\n",
        "\n",
        "            from bs4 import BeautifulSoup\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Extract title\n",
        "            title_elem = soup.find('h1', class_='js-issue-title')\n",
        "            if not title_elem:\n",
        "                title_elem = soup.find('bdi', class_='js-issue-title')\n",
        "            title = title_elem.get_text().strip() if title_elem else \"No title\"\n",
        "\n",
        "            # Extract body\n",
        "            body_elem = soup.find('td', class_='d-block comment-body markdown-body')\n",
        "            if not body_elem:\n",
        "                body_elem = soup.find('div', class_='comment-body')\n",
        "            body = body_elem.get_text().strip() if body_elem else \"\"\n",
        "\n",
        "            # Extract comments\n",
        "            comments = []\n",
        "            comment_elements = soup.find_all('td', class_='d-block comment-body markdown-body')\n",
        "            for comment_elem in comment_elements[1:6]:  # Skip first (main issue), take next 5\n",
        "                comment_text = comment_elem.get_text().strip()\n",
        "                if len(comment_text) > 10:\n",
        "                    comments.append(comment_text)\n",
        "\n",
        "            # Extract labels\n",
        "            labels = []\n",
        "            label_elements = soup.find_all('a', class_='Link--muted')\n",
        "            for label_elem in label_elements:\n",
        "                if 'labels' in label_elem.get('href', ''):\n",
        "                    labels.append(label_elem.get_text().strip())\n",
        "\n",
        "            full_content = f\"{title}\\n\\n{body}\\n\\n\" + \"\\n\\n\".join(comments)\n",
        "            code_snippets = self.extract_code_snippets(full_content)\n",
        "            error_traces = self.extract_error_traces(full_content)\n",
        "            language = self.detect_programming_language(repo, full_content)\n",
        "\n",
        "            return EnhancedIssueData(\n",
        "                url=url,\n",
        "                title=title,\n",
        "                body=body,\n",
        "                repository=f\"{owner}/{repo}\",\n",
        "                issue_number=issue_num,\n",
        "                labels=labels,\n",
        "                comments=comments,\n",
        "                code_snippets=code_snippets[:5],\n",
        "                error_traces=error_traces[:3],\n",
        "                language=language,\n",
        "                created_at=None,\n",
        "                state=None\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Web fetch failed for {url}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def extract_issue_info(self, url: str) -> Optional[EnhancedIssueData]:\n",
        "        \"\"\"Main method to extract issue info - tries API first, then web scraping\"\"\"\n",
        "        try:\n",
        "            owner, repo, issue_num = self.extract_repo_info(url)\n",
        "        except ValueError as e:\n",
        "            print(f\"URL parsing error: {e}\")\n",
        "            return None\n",
        "\n",
        "        # Try API first (more reliable)\n",
        "        issue_data = self.fetch_issue_via_api(owner, repo, issue_num)\n",
        "\n",
        "        # Fallback to web scraping if API fails\n",
        "        if not issue_data:\n",
        "            print(f\"Falling back to web scraping for {url}\")\n",
        "            issue_data = self.fetch_issue_via_web(url)\n",
        "\n",
        "        return issue_data"
      ],
      "metadata": {
        "id": "zy9QPo_Rc5we"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM-BASED BUG CLASSIFIER"
      ],
      "metadata": {
        "id": "ogN2mrDjc9qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedLLMBugClassifier:\n",
        "    \"\"\"Enhanced LLM-based bug classifier with better prompting and context\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model: str = LLM_MODEL):\n",
        "        self.client = instructor.from_openai(OpenAI(api_key=api_key))\n",
        "        self.model = model\n",
        "        self.examples_by_category = {}\n",
        "\n",
        "    def set_examples(self, examples: Dict[str, List[str]]):\n",
        "        \"\"\"Set few-shot examples for classification\"\"\"\n",
        "        self.examples_by_category = examples\n",
        "\n",
        "    def create_enhanced_classification_prompt(self, issue: EnhancedIssueData) -> str:\n",
        "        \"\"\"Create comprehensive prompt with all available context\"\"\"\n",
        "\n",
        "        # Build context sections\n",
        "        context_sections = []\n",
        "\n",
        "        # Basic info section\n",
        "        context_sections.append(f\"**REPOSITORY**: {issue.repository}\")\n",
        "        context_sections.append(f\"**TITLE**: {issue.title}\")\n",
        "\n",
        "        if issue.language:\n",
        "            context_sections.append(f\"**LANGUAGE**: {issue.language}\")\n",
        "\n",
        "        if issue.labels:\n",
        "            context_sections.append(f\"**LABELS**: {', '.join(issue.labels)}\")\n",
        "\n",
        "        # Main description\n",
        "        if issue.body:\n",
        "            context_sections.append(f\"**DESCRIPTION**:\\n{issue.body[:1500]}\")\n",
        "\n",
        "        # Code snippets\n",
        "        if issue.code_snippets:\n",
        "            context_sections.append(\"**CODE SNIPPETS**:\")\n",
        "            for i, snippet in enumerate(issue.code_snippets[:3], 1):\n",
        "                snippet_text = snippet[:300] if len(snippet) > 300 else snippet\n",
        "                context_sections.append(f\"{i}. ```\\n{snippet_text}\\n```\")\n",
        "\n",
        "        # Error traces\n",
        "        if issue.error_traces:\n",
        "            context_sections.append(\"**ERROR TRACES/LOGS**:\")\n",
        "            for i, trace in enumerate(issue.error_traces[:2], 1):\n",
        "                trace_text = trace[:400] if len(trace) > 400 else trace\n",
        "                context_sections.append(f\"{i}. {trace_text}\")\n",
        "\n",
        "        # Comments (most relevant ones)\n",
        "        if issue.comments:\n",
        "            context_sections.append(\"**RELEVANT COMMENTS**:\")\n",
        "            for i, comment in enumerate(issue.comments[:2], 1):\n",
        "                comment_text = comment[:300] if len(comment) > 300 else comment\n",
        "                context_sections.append(f\"{i}. {comment_text}\")\n",
        "\n",
        "        issue_context = \"\\n\\n\".join(context_sections)\n",
        "\n",
        "        # Build few-shot examples\n",
        "        examples_text = self._build_examples_text()\n",
        "\n",
        "        prompt = f\"\"\"You are an expert software engineer specializing in bug classification.\n",
        "Classify this GitHub issue into one of four categories based on the comprehensive context provided.\n",
        "\n",
        "**CATEGORY DEFINITIONS:**\n",
        "\n",
        "- **SEMANTIC**: API misuse, incorrect logic, specification violations, interface contract errors, wrong parameter usage, missing null checks, incorrect algorithm implementation\n",
        "- **MEMORY**: Memory leaks, out-of-memory errors, resource management issues, garbage collection problems, buffer overflows, memory allocation failures\n",
        "- **CONCURRENCY**: Thread safety issues, race conditions, deadlocks, synchronization problems, parallel processing errors, atomic operation failures\n",
        "- **OTHER**: Configuration errors, build issues, documentation problems, environment setup, dependency conflicts, deployment issues\n",
        "\n",
        "**CLASSIFICATION EXAMPLES:**\n",
        "{examples_text}\n",
        "\n",
        "**ISSUE TO CLASSIFY:**\n",
        "{issue_context}\n",
        "\n",
        "**CLASSIFICATION GUIDELINES:**\n",
        "1. **Primary focus**: Analyze the root cause described in the issue, not just symptoms\n",
        "2. **Code analysis**: Pay special attention to code snippets and error traces\n",
        "3. **Context clues**: Use repository language, labels, and comments for additional context\n",
        "4. **Error patterns**: Look for specific error messages that indicate category type\n",
        "5. **Multi-category handling**: If multiple categories apply, choose the most fundamental cause\n",
        "6. **Confidence scoring**: Base confidence on clarity of technical details provided\n",
        "\n",
        "Provide a structured classification with detailed reasoning.\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def _build_examples_text(self) -> str:\n",
        "        \"\"\"Build few-shot examples text\"\"\"\n",
        "        examples_text = \"\"\n",
        "        for category, examples in self.examples_by_category.items():\n",
        "            category_desc = self._get_category_description(category)\n",
        "            examples_text += f\"\\n**{category.upper()}** examples:\\n\"\n",
        "\n",
        "            for i, example in enumerate(examples[:2], 1):\n",
        "                repo_name = example.get('repository', 'Unknown')\n",
        "                examples_text += f\"  {i}. {repo_name} - {category_desc}\\n\"\n",
        "\n",
        "        return examples_text\n",
        "\n",
        "    def _get_category_description(self, category: str) -> str:\n",
        "        \"\"\"Get brief description for each category\"\"\"\n",
        "        descriptions = {\n",
        "            \"semantic\": \"Logic/API misuse issues\",\n",
        "            \"memory\": \"Memory management problems\",\n",
        "            \"concurrency\": \"Threading/synchronization issues\",\n",
        "            \"other\": \"Config/build/environment issues\"\n",
        "        }\n",
        "        return descriptions.get(category, \"Unknown category\")\n",
        "\n",
        "    def classify_issue(self, issue: EnhancedIssueData, max_retries: int = 3) -> Optional[BugClassification]:\n",
        "        \"\"\"Classify a single issue using enhanced prompting\"\"\"\n",
        "\n",
        "        prompt = self.create_enhanced_classification_prompt(issue)\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                classification = self.client.chat.completions.create(\n",
        "                    model=self.model,\n",
        "                    response_model=BugClassification,\n",
        "                    messages=[\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": \"You are an expert software bug classifier. Analyze the provided context comprehensively and provide accurate classifications with detailed reasoning.\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": prompt\n",
        "                        }\n",
        "                    ],\n",
        "                    max_tokens=1000,\n",
        "                )\n",
        "\n",
        "                return classification\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Classification attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(2 ** attempt)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def classify_batch(self, issues: List[EnhancedIssueData], progress_callback=None) -> List[Optional[BugClassification]]:\n",
        "        \"\"\"Classify multiple issues with progress tracking\"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, issue in enumerate(issues):\n",
        "            if progress_callback:\n",
        "                progress_callback(i, len(issues))\n",
        "\n",
        "            result = self.classify_issue(issue)\n",
        "            results.append(result)\n",
        "\n",
        "            # Rate limiting\n",
        "            time.sleep(1.0)\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "aTUq0hbVc_Am"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET LOADING AND PREPROCESSING"
      ],
      "metadata": {
        "id": "RJKPj5CEakBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedBugDatasetLoader:\n",
        "    \"\"\"Enhanced dataset loader with better example selection\"\"\"\n",
        "\n",
        "    def __init__(self, csv_path: str = '/content/bug_classification_dataset.csv'):\n",
        "        self.csv_path = csv_path\n",
        "        self.df = None\n",
        "        self.examples_by_category = {}\n",
        "\n",
        "    def load_dataset(self) -> Optional[pd.DataFrame]:\n",
        "        \"\"\"Load and validate the dataset\"\"\"\n",
        "        try:\n",
        "            self.df = pd.read_csv(self.csv_path)\n",
        "            print(f\"✅ Dataset loaded: {len(self.df)} records\")\n",
        "\n",
        "            # Validate required columns\n",
        "            required_cols = ['url', 'answer']\n",
        "            missing_cols = [col for col in required_cols if col not in self.df.columns]\n",
        "            if missing_cols:\n",
        "                print(f\"❌ Missing required columns: {missing_cols}\")\n",
        "                return None\n",
        "\n",
        "            # Show category distribution\n",
        "            print(f\"📊 Category distribution:\")\n",
        "            for category, count in self.df['answer'].value_counts().items():\n",
        "                print(f\"   {category}: {count}\")\n",
        "\n",
        "            return self.df\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"❌ Dataset file not found: {self.csv_path}\")\n",
        "            print(\"Please ensure the file exists at the specified path\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading dataset: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def prepare_enhanced_examples(self, n_examples_per_category: int = 3) -> Dict[str, List[Dict]]:\n",
        "        \"\"\"Prepare enhanced examples with better diversity\"\"\"\n",
        "        if self.df is None:\n",
        "            print(\"❌ Dataset not loaded\")\n",
        "            return {}\n",
        "\n",
        "        examples = {}\n",
        "        for category in BugCategory:\n",
        "            category_data = self.df[self.df['answer'] == category.value]\n",
        "\n",
        "            if len(category_data) > 0:\n",
        "                # Get diverse examples from different repositories\n",
        "                if 'repo' in category_data.columns:\n",
        "                    # Group by repository and take diverse samples\n",
        "                    diverse_samples = category_data.groupby('repo', group_keys=False).apply(\n",
        "                        lambda x: x.sample(min(len(x), 1), random_state=42)\n",
        "                    ).head(n_examples_per_category)\n",
        "                else:\n",
        "                    # Random sample if no repo column\n",
        "                    diverse_samples = category_data.sample(\n",
        "                        n=min(n_examples_per_category, len(category_data)),\n",
        "                        random_state=42\n",
        "                    )\n",
        "\n",
        "                examples[category.value] = []\n",
        "                for _, row in diverse_samples.iterrows():\n",
        "                    example = {\n",
        "                        'url': row['url'],\n",
        "                        'repository': row.get('repo', 'unknown'),\n",
        "                        'category': category.value,\n",
        "                        'annotation_time': row.get('time_spent', 30.0)\n",
        "                    }\n",
        "                    examples[category.value].append(example)\n",
        "\n",
        "        self.examples_by_category = examples\n",
        "        return examples"
      ],
      "metadata": {
        "id": "gm0jMSLoamdF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVALUATION AND METRICS"
      ],
      "metadata": {
        "id": "14ZCjnv_d-sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedBugClassifierEvaluator:\n",
        "    \"\"\"Enhanced evaluation with more detailed metrics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.categories = [cat.value for cat in BugCategory]\n",
        "\n",
        "    def evaluate_predictions(self, y_true: List[str], y_pred: List[str],\n",
        "                           confidences: List[float] = None,\n",
        "                           detailed_results: List[BugClassification] = None) -> Dict:\n",
        "        \"\"\"Enhanced evaluation with confidence analysis\"\"\"\n",
        "\n",
        "        # Filter out None predictions\n",
        "        valid_indices = [i for i, pred in enumerate(y_pred) if pred is not None]\n",
        "        y_true_clean = [y_true[i] for i in valid_indices]\n",
        "        y_pred_clean = [y_pred[i] for i in valid_indices]\n",
        "\n",
        "        if confidences:\n",
        "            confidences_clean = [confidences[i] for i in valid_indices]\n",
        "        else:\n",
        "            confidences_clean = None\n",
        "\n",
        "        # Basic metrics\n",
        "        accuracy = accuracy_score(y_true_clean, y_pred_clean)\n",
        "\n",
        "        # Classification report\n",
        "        class_report = classification_report(\n",
        "            y_true_clean, y_pred_clean,\n",
        "            labels=self.categories,\n",
        "            target_names=self.categories,\n",
        "            output_dict=True,\n",
        "            zero_division=0\n",
        "        )\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_true_clean, y_pred_clean, labels=self.categories)\n",
        "\n",
        "        results = {\n",
        "            'accuracy': accuracy,\n",
        "            'classification_report': class_report,\n",
        "            'confusion_matrix': cm,\n",
        "            'categories': self.categories,\n",
        "            'total_predictions': len(y_true),\n",
        "            'successful_predictions': len(y_true_clean),\n",
        "            'failed_predictions': len(y_true) - len(y_true_clean)\n",
        "        }\n",
        "\n",
        "        # Confidence analysis\n",
        "        if confidences_clean:\n",
        "            results['avg_confidence'] = np.mean(confidences_clean)\n",
        "\n",
        "            # Confidence by correctness\n",
        "            correct_mask = [y_true_clean[i] == y_pred_clean[i] for i in range(len(y_true_clean))]\n",
        "            results['confidence_by_correctness'] = {\n",
        "                'correct': np.mean([confidences_clean[i] for i in range(len(confidences_clean)) if correct_mask[i]]) if any(correct_mask) else 0.0,\n",
        "                'incorrect': np.mean([confidences_clean[i] for i in range(len(confidences_clean)) if not correct_mask[i]]) if not all(correct_mask) else 0.0\n",
        "            }\n",
        "\n",
        "            # Confidence distribution by category\n",
        "            results['confidence_by_category'] = {}\n",
        "            for cat in self.categories:\n",
        "                cat_mask = [y_pred_clean[i] == cat for i in range(len(y_pred_clean))]\n",
        "                if any(cat_mask):\n",
        "                    results['confidence_by_category'][cat] = np.mean([\n",
        "                        confidences_clean[i] for i in range(len(confidences_clean)) if cat_mask[i]\n",
        "                    ])\n",
        "\n",
        "        return results\n",
        "\n",
        "    def print_enhanced_evaluation_report(self, results: Dict):\n",
        "        \"\"\"Print comprehensive evaluation results\"\"\"\n",
        "        print(\"=\" * 70)\n",
        "        print(\"🎯 ENHANCED BUG CLASSIFICATION EVALUATION RESULTS\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        print(f\"\\n📊 **Prediction Statistics**:\")\n",
        "        print(f\"   Total issues: {results['total_predictions']}\")\n",
        "        print(f\"   Successful predictions: {results['successful_predictions']}\")\n",
        "        print(f\"   Failed predictions: {results['failed_predictions']}\")\n",
        "        print(f\"   Success rate: {results['successful_predictions']/results['total_predictions']*100:.1f}%\")\n",
        "\n",
        "        print(f\"\\n🎯 **Overall Accuracy**: {results['accuracy']:.3f}\")\n",
        "\n",
        "        if 'avg_confidence' in results:\n",
        "            print(f\"🎯 **Average Confidence**: {results['avg_confidence']:.3f}\")\n",
        "            conf_by_correct = results['confidence_by_correctness']\n",
        "            print(f\"   ✅ Correct predictions: {conf_by_correct['correct']:.3f}\")\n",
        "            print(f\"   ❌ Incorrect predictions: {conf_by_correct['incorrect']:.3f}\")\n",
        "\n",
        "            if 'confidence_by_category' in results:\n",
        "                print(f\"\\n📈 **Confidence by Category**:\")\n",
        "                for cat, conf in results['confidence_by_category'].items():\n",
        "                    print(f\"   {cat.upper():12}: {conf:.3f}\")\n",
        "\n",
        "        print(f\"\\n📈 **Per-Category Performance**:\")\n",
        "        class_report = results['classification_report']\n",
        "\n",
        "        for category in self.categories:\n",
        "            if category in class_report:\n",
        "                metrics = class_report[category]\n",
        "                print(f\"   {category.upper():12} - P: {metrics['precision']:.3f} | \"\n",
        "                     f\"R: {metrics['recall']:.3f} | F1: {metrics['f1-score']:.3f} | \"\n",
        "                     f\"Support: {metrics['support']:3d}\")\n",
        "\n",
        "        # Macro averages\n",
        "        if 'macro avg' in class_report:\n",
        "            macro_avg = class_report['macro avg']\n",
        "            print(f\"\\n🎯 **Macro Average** - P: {macro_avg['precision']:.3f} | \"\n",
        "                 f\"R: {macro_avg['recall']:.3f} | F1: {macro_avg['f1-score']:.3f}\")\n",
        "\n",
        "    def plot_enhanced_confusion_matrix(self, results: Dict, title: str = \"Bug Classification Confusion Matrix\"):\n",
        "        \"\"\"Plot enhanced confusion matrix with better visualization\"\"\"\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        cm = results['confusion_matrix']\n",
        "        categories = results['categories']\n",
        "\n",
        "        # Normalize confusion matrix\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Create heatmap\n",
        "        ax = sns.heatmap(\n",
        "            cm_normalized,\n",
        "            annot=True,\n",
        "            fmt='.2f',\n",
        "            xticklabels=[cat.upper() for cat in categories],\n",
        "            yticklabels=[cat.upper() for cat in categories],\n",
        "            cmap='Blues',\n",
        "            cbar_kws={'label': 'Normalized Frequency'}\n",
        "        )\n",
        "\n",
        "        # Add raw counts as text\n",
        "        for i in range(len(categories)):\n",
        "            for j in range(len(categories)):\n",
        "                if cm[i, j] > 0:\n",
        "                    ax.text(j + 0.5, i + 0.7, f'({cm[i, j]})',\n",
        "                           ha='center', va='center', fontsize=9, color='red')\n",
        "\n",
        "        plt.title(f'{title}\\n(Normalized values with raw counts in parentheses)', fontsize=14, pad=20)\n",
        "        plt.xlabel('Predicted Category', fontsize=12)\n",
        "        plt.ylabel('True Category', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "c_z37aOfd_l1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BASELINE TRADITIONAL ML CLASSIFIER"
      ],
      "metadata": {
        "id": "Al1IDhBCeJNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineBugClassifier:\n",
        "    \"\"\"Traditional ML baseline for comparison\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "        self.classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
        "        self.is_trained = False\n",
        "\n",
        "    def prepare_text(self, df: pd.DataFrame) -> List[str]:\n",
        "        \"\"\"Prepare text data for traditional ML\"\"\"\n",
        "        texts = []\n",
        "        for _, row in df.iterrows():\n",
        "            # Combine URL info with repository context\n",
        "            repo_name = row['repo'].split('/')[-1] if '/' in row['repo'] else row['repo']\n",
        "            text = f\"{repo_name} github issue\"  # Simple text representation\n",
        "            texts.append(text)\n",
        "        return texts\n",
        "\n",
        "    def train(self, df: pd.DataFrame):\n",
        "        \"\"\"Train baseline classifier\"\"\"\n",
        "        texts = self.prepare_text(df)\n",
        "        X = self.vectorizer.fit_transform(texts)\n",
        "        y = df['answer'].values\n",
        "\n",
        "        self.classifier.fit(X, y)\n",
        "        self.is_trained = True\n",
        "        print(\"Baseline model trained\")\n",
        "\n",
        "    def predict(self, df: pd.DataFrame) -> Tuple[List[str], List[float]]:\n",
        "        \"\"\"Make predictions with baseline model\"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"Model must be trained first\")\n",
        "\n",
        "        texts = self.prepare_text(df)\n",
        "        X = self.vectorizer.transform(texts)\n",
        "\n",
        "        predictions = self.classifier.predict(X)\n",
        "        probabilities = self.classifier.predict_proba(X)\n",
        "        confidences = [max(prob) for prob in probabilities]\n",
        "\n",
        "        return predictions.tolist(), confidences"
      ],
      "metadata": {
        "id": "JAII7zlQeK7T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN EXECUTION PIPELINE"
      ],
      "metadata": {
        "id": "nkU1DEMTeQGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedBugClassificationPipeline:\n",
        "    \"\"\"Main pipeline with enhanced issue fetching and classification\"\"\"\n",
        "\n",
        "    def __init__(self, openai_api_key: str, github_token: Optional[str] = None):\n",
        "        self.dataset_loader = EnhancedBugDatasetLoader()\n",
        "        self.issue_fetcher = EnhancedGitHubIssueFetcher(github_token)\n",
        "        self.classifier = EnhancedLLMBugClassifier(openai_api_key)\n",
        "        self.evaluator = EnhancedBugClassifierEvaluator()\n",
        "\n",
        "    def run_enhanced_pipeline(self, sample_size: int = 20):\n",
        "        \"\"\"Run enhanced pipeline with real GitHub issue fetching\"\"\"\n",
        "\n",
        "        print(\"🚀 STARTING ENHANCED BUG CLASSIFICATION PIPELINE\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Step 1: Load Dataset\n",
        "        print(\"\\n📂 Step 1: Loading dataset...\")\n",
        "        df = self.dataset_loader.load_dataset()\n",
        "        if df is None:\n",
        "            return None\n",
        "\n",
        "        # Step 2: Prepare examples\n",
        "        print(\"\\n📚 Step 2: Preparing few-shot examples...\")\n",
        "        examples = self.dataset_loader.prepare_enhanced_examples(n_examples_per_category=3)\n",
        "        self.classifier.set_examples(examples)\n",
        "\n",
        "        for category, category_examples in examples.items():\n",
        "            print(f\"   {category.upper()}: {len(category_examples)} examples\")\n",
        "\n",
        "        # Step 3: Create evaluation dataset\n",
        "        print(f\"\\n✂️  Step 3: Preparing evaluation dataset (sample size: {sample_size})...\")\n",
        "\n",
        "        # Get a diverse sample for evaluation\n",
        "        if len(df) > sample_size:\n",
        "            # Stratified sampling to maintain category balance\n",
        "            test_sample = df.groupby('answer', group_keys=False).apply(\n",
        "                lambda x: x.sample(min(len(x), sample_size // 4), random_state=42)\n",
        "            ).head(sample_size)\n",
        "        else:\n",
        "            test_sample = df.copy()\n",
        "\n",
        "        print(f\"   📊 Selected {len(test_sample)} issues for evaluation\")\n",
        "        print(f\"   📊 Category distribution: {test_sample['answer'].value_counts().to_dict()}\")\n",
        "\n",
        "        # Step 4: Fetch real GitHub issue content\n",
        "        print(f\"\\n📡 Step 4: Fetching GitHub issue content...\")\n",
        "        enhanced_issues = []\n",
        "        fetch_failures = 0\n",
        "\n",
        "        for i, (_, row) in enumerate(test_sample.iterrows()):\n",
        "            print(f\"   Fetching {i+1}/{len(test_sample)}: {row['url']}\")\n",
        "\n",
        "            issue_data = self.issue_fetcher.extract_issue_info(row['url'])\n",
        "            if issue_data:\n",
        "                enhanced_issues.append(issue_data)\n",
        "                # Show what we extracted\n",
        "                content_info = []\n",
        "                if issue_data.body and len(issue_data.body.strip()) > 0:\n",
        "                    content_info.append(\"description\")\n",
        "                if issue_data.comments:\n",
        "                    content_info.append(f\"{len(issue_data.comments)} comments\")\n",
        "                if issue_data.code_snippets:\n",
        "                    content_info.append(f\"{len(issue_data.code_snippets)} code snippets\")\n",
        "                if issue_data.error_traces:\n",
        "                    content_info.append(f\"{len(issue_data.error_traces)} error traces\")\n",
        "                if issue_data.labels:\n",
        "                    content_info.append(f\"{len(issue_data.labels)} labels\")\n",
        "\n",
        "                print(f\"      ✅ Extracted: {', '.join(content_info) if content_info else 'basic info only'}\")\n",
        "            else:\n",
        "                enhanced_issues.append(None)\n",
        "                fetch_failures += 1\n",
        "                print(f\"      ❌ Failed to fetch content\")\n",
        "\n",
        "            # Rate limiting\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        print(f\"   📊 Successfully fetched: {len(enhanced_issues) - fetch_failures}/{len(enhanced_issues)}\")\n",
        "        print(f\"   📊 Fetch failure rate: {fetch_failures/len(enhanced_issues)*100:.1f}%\")\n",
        "\n",
        "        # Step 5: Enhanced LLM Classification\n",
        "        print(f\"\\n🧠 Step 5: Enhanced LLM classification...\")\n",
        "\n",
        "        def progress_callback(current, total):\n",
        "            print(f\"      Progress: {current + 1}/{total} ({(current + 1)/total*100:.1f}%)\")\n",
        "\n",
        "        # Filter out failed fetches\n",
        "        valid_issues = [(issue, i) for i, issue in enumerate(enhanced_issues) if issue is not None]\n",
        "        valid_test_sample = test_sample.iloc[[i for issue, i in valid_issues]].reset_index(drop=True)\n",
        "        valid_enhanced_issues = [issue for issue, i in valid_issues]\n",
        "\n",
        "        print(f\"   📊 Classifying {len(valid_enhanced_issues)} successfully fetched issues...\")\n",
        "\n",
        "        classification_results = self.classifier.classify_batch(\n",
        "            valid_enhanced_issues,\n",
        "            progress_callback\n",
        "        )\n",
        "\n",
        "        # Step 6: Extract predictions and evaluate\n",
        "        print(f\"\\n📈 Step 6: Evaluation and analysis...\")\n",
        "\n",
        "        true_labels = valid_test_sample['answer'].tolist()\n",
        "        llm_predictions = [r.category.value if r else \"other\" for r in classification_results]\n",
        "        llm_confidences = [r.confidence if r else 0.0 for r in classification_results]\n",
        "\n",
        "        # Evaluate results\n",
        "        evaluation_results = self.evaluator.evaluate_predictions(\n",
        "            true_labels, llm_predictions, llm_confidences, classification_results\n",
        "        )\n",
        "\n",
        "        # Print detailed results\n",
        "        print(f\"\\n🎯 ENHANCED LLM CLASSIFIER RESULTS:\")\n",
        "        self.evaluator.print_enhanced_evaluation_report(evaluation_results)\n",
        "\n",
        "        # Step 7: Detailed Analysis\n",
        "        print(f\"\\n🔍 Step 7: Detailed prediction analysis...\")\n",
        "        self._print_detailed_analysis(\n",
        "            valid_enhanced_issues, true_labels, llm_predictions,\n",
        "            llm_confidences, classification_results\n",
        "        )\n",
        "\n",
        "        # Step 8: Visualization\n",
        "        print(f\"\\n📊 Step 8: Generating visualizations...\")\n",
        "        self.evaluator.plot_enhanced_confusion_matrix(\n",
        "            evaluation_results,\n",
        "            \"Enhanced LLM Bug Classifier - Confusion Matrix\"\n",
        "        )\n",
        "\n",
        "        # Additional analysis plots\n",
        "        self._plot_confidence_analysis(llm_confidences, true_labels, llm_predictions)\n",
        "        self._plot_category_performance(evaluation_results)\n",
        "\n",
        "        print(f\"\\n🎉 ENHANCED PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "\n",
        "        return {\n",
        "            'evaluation_results': evaluation_results,\n",
        "            'test_data': valid_test_sample,\n",
        "            'enhanced_issues': valid_enhanced_issues,\n",
        "            'predictions': {\n",
        "                'true': true_labels,\n",
        "                'predicted': llm_predictions,\n",
        "                'confidences': llm_confidences\n",
        "            },\n",
        "            'classification_details': classification_results\n",
        "        }\n",
        "\n",
        "    def _print_detailed_analysis(self, issues: List[EnhancedIssueData],\n",
        "                               true_labels: List[str], predictions: List[str],\n",
        "                               confidences: List[float],\n",
        "                               classification_results: List[BugClassification]):\n",
        "        \"\"\"Print detailed analysis of predictions\"\"\"\n",
        "\n",
        "        print(\"=\" * 70)\n",
        "        print(\"🔍 DETAILED PREDICTION ANALYSIS\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Group by prediction accuracy\n",
        "        correct_predictions = []\n",
        "        incorrect_predictions = []\n",
        "\n",
        "        for i, (issue, true_label, pred, conf, result) in enumerate(\n",
        "            zip(issues, true_labels, predictions, confidences, classification_results)\n",
        "        ):\n",
        "            analysis = {\n",
        "                'index': i,\n",
        "                'issue': issue,\n",
        "                'true_label': true_label,\n",
        "                'predicted': pred,\n",
        "                'confidence': conf,\n",
        "                'result': result,\n",
        "                'correct': true_label == pred\n",
        "            }\n",
        "\n",
        "            if analysis['correct']:\n",
        "                correct_predictions.append(analysis)\n",
        "            else:\n",
        "                incorrect_predictions.append(analysis)\n",
        "\n",
        "        # Show some correct predictions\n",
        "        print(f\"\\n✅ CORRECT PREDICTIONS (showing top 3 by confidence):\")\n",
        "        correct_sorted = sorted(correct_predictions, key=lambda x: x['confidence'], reverse=True)\n",
        "        for analysis in correct_sorted[:3]:\n",
        "            self._print_prediction_details(analysis)\n",
        "\n",
        "        # Show some incorrect predictions\n",
        "        print(f\"\\n❌ INCORRECT PREDICTIONS (showing top 3 by confidence):\")\n",
        "        incorrect_sorted = sorted(incorrect_predictions, key=lambda x: x['confidence'], reverse=True)\n",
        "        for analysis in incorrect_sorted[:3]:\n",
        "            self._print_prediction_details(analysis)\n",
        "\n",
        "        # Show low confidence predictions\n",
        "        all_predictions = correct_predictions + incorrect_predictions\n",
        "        low_confidence = sorted([p for p in all_predictions if p['confidence'] < 0.6],\n",
        "                              key=lambda x: x['confidence'])\n",
        "\n",
        "        if low_confidence:\n",
        "            print(f\"\\n⚠️  LOW CONFIDENCE PREDICTIONS (< 0.6, showing first 2):\")\n",
        "            for analysis in low_confidence[:2]:\n",
        "                self._print_prediction_details(analysis)\n",
        "\n",
        "    def _print_prediction_details(self, analysis: Dict):\n",
        "        \"\"\"Print details for a single prediction\"\"\"\n",
        "        issue = analysis['issue']\n",
        "        result = analysis['result']\n",
        "        status = \"✅\" if analysis['correct'] else \"❌\"\n",
        "\n",
        "        print(f\"\\n{status} Issue: {issue.repository}/issues/{issue.issue_number}\")\n",
        "        print(f\"   📋 Title: {issue.title[:80]}...\")\n",
        "        print(f\"   🎯 True: {analysis['true_label']} | Predicted: {analysis['predicted']} | Confidence: {analysis['confidence']:.3f}\")\n",
        "\n",
        "        if result and result.reasoning:\n",
        "            reasoning = result.reasoning[:150] + \"...\" if len(result.reasoning) > 150 else result.reasoning\n",
        "            print(f\"   💭 Reasoning: {reasoning}\")\n",
        "\n",
        "        # Show extracted features\n",
        "        features = []\n",
        "        if issue.language:\n",
        "            features.append(f\"Language: {issue.language}\")\n",
        "        if issue.labels:\n",
        "            features.append(f\"Labels: {', '.join(issue.labels[:3])}\")\n",
        "        if issue.code_snippets:\n",
        "            features.append(f\"Code snippets: {len(issue.code_snippets)}\")\n",
        "        if issue.error_traces:\n",
        "            features.append(f\"Error traces: {len(issue.error_traces)}\")\n",
        "        if issue.comments:\n",
        "            features.append(f\"Comments: {len(issue.comments)}\")\n",
        "\n",
        "        if features:\n",
        "            print(f\"   🔍 Features: {' | '.join(features)}\")\n",
        "\n",
        "    def _plot_confidence_analysis(self, confidences: List[float],\n",
        "                                true_labels: List[str], predictions: List[str]):\n",
        "        \"\"\"Plot confidence distribution and analysis\"\"\"\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "        # Confidence distribution\n",
        "        ax1.hist(confidences, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        ax1.set_xlabel('Confidence Score')\n",
        "        ax1.set_ylabel('Frequency')\n",
        "        ax1.set_title('Distribution of Prediction Confidence')\n",
        "        ax1.axvline(np.mean(confidences), color='red', linestyle='--',\n",
        "                   label=f'Mean: {np.mean(confidences):.3f}')\n",
        "        ax1.legend()\n",
        "\n",
        "        # Confidence by correctness\n",
        "        correct_mask = [true_labels[i] == predictions[i] for i in range(len(true_labels))]\n",
        "        correct_conf = [confidences[i] for i in range(len(confidences)) if correct_mask[i]]\n",
        "        incorrect_conf = [confidences[i] for i in range(len(confidences)) if not correct_mask[i]]\n",
        "\n",
        "        ax2.boxplot([correct_conf, incorrect_conf], labels=['Correct', 'Incorrect'])\n",
        "        ax2.set_ylabel('Confidence Score')\n",
        "        ax2.set_title('Confidence by Prediction Accuracy')\n",
        "\n",
        "        # Confidence by category\n",
        "        categories = list(set(predictions))\n",
        "        conf_by_cat = {cat: [confidences[i] for i in range(len(confidences))\n",
        "                            if predictions[i] == cat] for cat in categories}\n",
        "\n",
        "        ax3.boxplot([conf_by_cat[cat] for cat in categories], labels=categories)\n",
        "        ax3.set_ylabel('Confidence Score')\n",
        "        ax3.set_title('Confidence Distribution by Predicted Category')\n",
        "        ax3.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Confidence vs Accuracy scatter\n",
        "        accuracy_by_conf_bin = []\n",
        "        conf_bins = np.linspace(0, 1, 11)\n",
        "        bin_centers = []\n",
        "\n",
        "        for i in range(len(conf_bins) - 1):\n",
        "            bin_mask = [(confidences[j] >= conf_bins[i] and confidences[j] < conf_bins[i+1])\n",
        "                       for j in range(len(confidences))]\n",
        "            if any(bin_mask):\n",
        "                bin_accuracy = np.mean([correct_mask[j] for j in range(len(correct_mask)) if bin_mask[j]])\n",
        "                accuracy_by_conf_bin.append(bin_accuracy)\n",
        "                bin_centers.append((conf_bins[i] + conf_bins[i+1]) / 2)\n",
        "\n",
        "        if bin_centers:\n",
        "            ax4.scatter(bin_centers, accuracy_by_conf_bin, alpha=0.7, s=60)\n",
        "            ax4.plot(bin_centers, accuracy_by_conf_bin, 'r--', alpha=0.5)\n",
        "            ax4.set_xlabel('Confidence Score')\n",
        "            ax4.set_ylabel('Accuracy')\n",
        "            ax4.set_title('Accuracy vs Confidence Score')\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def _plot_category_performance(self, evaluation_results: Dict):\n",
        "        \"\"\"Plot detailed category performance analysis\"\"\"\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        class_report = evaluation_results['classification_report']\n",
        "        categories = evaluation_results['categories']\n",
        "\n",
        "        # Per-category metrics\n",
        "        metrics = ['precision', 'recall', 'f1-score']\n",
        "        metric_values = {metric: [] for metric in metrics}\n",
        "\n",
        "        for category in categories:\n",
        "            if category in class_report:\n",
        "                for metric in metrics:\n",
        "                    metric_values[metric].append(class_report[category][metric])\n",
        "            else:\n",
        "                for metric in metrics:\n",
        "                    metric_values[metric].append(0.0)\n",
        "\n",
        "        x = np.arange(len(categories))\n",
        "        width = 0.25\n",
        "\n",
        "        for i, metric in enumerate(metrics):\n",
        "            ax1.bar(x + i * width, metric_values[metric], width,\n",
        "                   label=metric.capitalize(), alpha=0.8)\n",
        "\n",
        "        ax1.set_xlabel('Categories')\n",
        "        ax1.set_ylabel('Score')\n",
        "        ax1.set_title('Per-Category Performance Metrics')\n",
        "        ax1.set_xticks(x + width)\n",
        "        ax1.set_xticklabels([cat.upper() for cat in categories])\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Support (number of samples) per category\n",
        "        support_values = []\n",
        "        for category in categories:\n",
        "            if category in class_report:\n",
        "                support_values.append(class_report[category]['support'])\n",
        "            else:\n",
        "                support_values.append(0)\n",
        "\n",
        "        ax2.bar(categories, support_values, alpha=0.7, color='lightcoral')\n",
        "        ax2.set_xlabel('Categories')\n",
        "        ax2.set_ylabel('Number of Samples')\n",
        "        ax2.set_title('Dataset Support per Category')\n",
        "        ax2.set_xticklabels([cat.upper() for cat in categories])\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for i, v in enumerate(support_values):\n",
        "            ax2.text(i, v + 0.1, str(v), ha='center', va='bottom')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "n2h8Wae-eRan"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UTILITY FUNCTIONS FOR PRODUCTION USE"
      ],
      "metadata": {
        "id": "DCY9YjDHelR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_single_issue(url: str, openai_api_key: str,\n",
        "                         github_token: Optional[str] = None) -> Optional[BugClassification]:\n",
        "    \"\"\"Classify a single GitHub issue URL with enhanced content extraction\"\"\"\n",
        "\n",
        "    print(f\"🔍 Analyzing issue: {url}\")\n",
        "\n",
        "    # Initialize components\n",
        "    fetcher = EnhancedGitHubIssueFetcher(github_token)\n",
        "    classifier = EnhancedLLMBugClassifier(openai_api_key)\n",
        "\n",
        "    # Set up basic examples (in production, load from your dataset)\n",
        "    basic_examples = {\n",
        "        'semantic': [{'repository': 'spring-boot', 'category': 'semantic', 'annotation_time': 45.0}],\n",
        "        'memory': [{'repository': 'elasticsearch', 'category': 'memory', 'annotation_time': 52.0}],\n",
        "        'concurrency': [{'repository': 'netty', 'category': 'concurrency', 'annotation_time': 23.0}],\n",
        "        'other': [{'repository': 'gradle', 'category': 'other', 'annotation_time': 15.0}]\n",
        "    }\n",
        "    classifier.set_examples(basic_examples)\n",
        "\n",
        "    # Fetch enhanced issue data\n",
        "    issue_data = fetcher.extract_issue_info(url)\n",
        "    if not issue_data:\n",
        "        print(\"❌ Failed to fetch issue data\")\n",
        "        return None\n",
        "\n",
        "    print(f\"📋 Issue: {issue_data.title}\")\n",
        "    print(f\"🏠 Repository: {issue_data.repository}\")\n",
        "\n",
        "    # Show extracted features\n",
        "    features = []\n",
        "    if issue_data.language:\n",
        "        features.append(f\"Language: {issue_data.language}\")\n",
        "    if issue_data.labels:\n",
        "        features.append(f\"Labels: {len(issue_data.labels)}\")\n",
        "    if issue_data.code_snippets:\n",
        "        features.append(f\"Code: {len(issue_data.code_snippets)} snippets\")\n",
        "    if issue_data.error_traces:\n",
        "        features.append(f\"Errors: {len(issue_data.error_traces)} traces\")\n",
        "    if issue_data.comments:\n",
        "        features.append(f\"Comments: {len(issue_data.comments)}\")\n",
        "\n",
        "    if features:\n",
        "        print(f\"🔍 Extracted features: {' | '.join(features)}\")\n",
        "\n",
        "    # Classify\n",
        "    result = classifier.classify_issue(issue_data)\n",
        "\n",
        "    if result:\n",
        "        print(f\"\\n🎯 Classification: {result.category.value}\")\n",
        "        print(f\"📊 Confidence: {result.confidence:.3f}\")\n",
        "        print(f\"💭 Reasoning: {result.reasoning}\")\n",
        "\n",
        "        if result.secondary_categories:\n",
        "            print(f\"🔄 Secondary categories: {[cat.value for cat in result.secondary_categories]}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def batch_classify_with_enhanced_features(csv_file: str, openai_api_key: str,\n",
        "                                        github_token: Optional[str] = None,\n",
        "                                        output_file: str = \"enhanced_classification_results.csv\",\n",
        "                                        max_issues: int = 100):\n",
        "    \"\"\"Enhanced batch classification with comprehensive feature extraction\"\"\"\n",
        "\n",
        "    print(f\"🚀 ENHANCED BATCH CLASSIFICATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load input data\n",
        "    try:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        if 'url' not in df.columns:\n",
        "            print(\"❌ CSV must contain 'url' column\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Limit processing if requested\n",
        "    if len(df) > max_issues:\n",
        "        print(f\"⚠️ Limiting to first {max_issues} issues (from {len(df)} total)\")\n",
        "        df = df.head(max_issues)\n",
        "\n",
        "    # Initialize components\n",
        "    fetcher = EnhancedGitHubIssueFetcher(github_token)\n",
        "    classifier = EnhancedLLMBugClassifier(openai_api_key)\n",
        "\n",
        "    # Set basic examples\n",
        "    basic_examples = {\n",
        "        'semantic': [{'repository': 'spring-boot', 'category': 'semantic', 'annotation_time': 45.0}],\n",
        "        'memory': [{'repository': 'elasticsearch', 'category': 'memory', 'annotation_time': 52.0}],\n",
        "        'concurrency': [{'repository': 'netty', 'category': 'concurrency', 'annotation_time': 23.0}],\n",
        "        'other': [{'repository': 'gradle', 'category': 'other', 'annotation_time': 15.0}]\n",
        "    }\n",
        "    classifier.set_examples(basic_examples)\n",
        "\n",
        "    results = []\n",
        "    fetch_failures = 0\n",
        "    classification_failures = 0\n",
        "\n",
        "    print(f\"📡 Processing {len(df)} issues...\")\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        print(f\"Progress: {i+1}/{len(df)} - {row['url']}\")\n",
        "\n",
        "        # Fetch enhanced issue data\n",
        "        issue_data = fetcher.extract_issue_info(row['url'])\n",
        "\n",
        "        if not issue_data:\n",
        "            fetch_failures += 1\n",
        "            print(f\"   ❌ Failed to fetch issue content\")\n",
        "\n",
        "            # Create minimal result for failed fetch\n",
        "            result = {\n",
        "                'url': row['url'],\n",
        "                'repository': 'unknown',\n",
        "                'title': 'Failed to fetch',\n",
        "                'fetch_success': False,\n",
        "                'predicted_category': 'unknown',\n",
        "                'confidence': 0.0,\n",
        "                'reasoning': 'Failed to fetch issue content',\n",
        "                'language': None,\n",
        "                'num_labels': 0,\n",
        "                'num_comments': 0,\n",
        "                'num_code_snippets': 0,\n",
        "                'num_error_traces': 0,\n",
        "                'has_description': False\n",
        "            }\n",
        "        else:\n",
        "            print(f\"   ✅ Fetched content\")\n",
        "\n",
        "            # Classify\n",
        "            classification = classifier.classify_issue(issue_data)\n",
        "\n",
        "            if classification:\n",
        "                print(f\"   🎯 Classified as: {classification.category.value} (confidence: {classification.confidence:.3f})\")\n",
        "            else:\n",
        "                classification_failures += 1\n",
        "                print(f\"   ❌ Classification failed\")\n",
        "\n",
        "            # Create comprehensive result\n",
        "            result = {\n",
        "                'url': row['url'],\n",
        "                'repository': issue_data.repository,\n",
        "                'title': issue_data.title,\n",
        "                'fetch_success': True,\n",
        "                'predicted_category': classification.category.value if classification else 'unknown',\n",
        "                'confidence': classification.confidence if classification else 0.0,\n",
        "                'reasoning': classification.reasoning if classification else 'Classification failed',\n",
        "                'secondary_categories': ','.join([cat.value for cat in classification.secondary_categories]) if classification and classification.secondary_categories else '',\n",
        "                'language': issue_data.language,\n",
        "                'labels': '|'.join(issue_data.labels) if issue_data.labels else '',\n",
        "                'num_labels': len(issue_data.labels),\n",
        "                'num_comments': len(issue_data.comments),\n",
        "                'num_code_snippets': len(issue_data.code_snippets),\n",
        "                'num_error_traces': len(issue_data.error_traces),\n",
        "                'has_description': len(issue_data.body.strip()) > 0 if issue_data.body else False,\n",
        "                'description_length': len(issue_data.body) if issue_data.body else 0,\n",
        "                'state': issue_data.state,\n",
        "                'created_at': issue_data.created_at\n",
        "            }\n",
        "\n",
        "        # Add original columns\n",
        "        for col in df.columns:\n",
        "            if col not in result:\n",
        "                result[f'original_{col}'] = row[col]\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "        # Rate limiting\n",
        "        time.sleep(1.0)\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv(output_file, index=False)\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n📊 BATCH CLASSIFICATION SUMMARY:\")\n",
        "    print(f\"   Total issues processed: {len(df)}\")\n",
        "    print(f\"   Successful fetches: {len(df) - fetch_failures}\")\n",
        "    print(f\"   Fetch failures: {fetch_failures}\")\n",
        "    print(f\"   Classification failures: {classification_failures}\")\n",
        "    print(f\"   Overall success rate: {(len(df) - fetch_failures - classification_failures) / len(df) * 100:.1f}%\")\n",
        "\n",
        "    # Category distribution\n",
        "    successful_classifications = results_df[results_df['predicted_category'] != 'unknown']\n",
        "    if len(successful_classifications) > 0:\n",
        "        print(f\"\\n📈 Predicted category distribution:\")\n",
        "        for category, count in successful_classifications['predicted_category'].value_counts().items():\n",
        "            print(f\"   {category}: {count}\")\n",
        "\n",
        "    print(f\"\\n✅ Results saved to: {output_file}\")\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "5UWlKQh9enLV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN EXECUTION"
      ],
      "metadata": {
        "id": "UxFX0w_Ieuai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the enhanced bug classification system\"\"\"\n",
        "\n",
        "    print(\"🚀 ENHANCED BUG CLASSIFICATION SYSTEM\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Check for dataset\n",
        "    import os\n",
        "    dataset_path = '/content/bug_classification_dataset.csv'\n",
        "\n",
        "    if not os.path.exists(dataset_path):\n",
        "        print(f\"❌ Dataset not found at: {dataset_path}\")\n",
        "        print(\"Please upload your dataset file first using the upload function below\")\n",
        "        return None\n",
        "\n",
        "    # Initialize enhanced pipeline\n",
        "    try:\n",
        "        pipeline = EnhancedBugClassificationPipeline(OPENAI_API_KEY, GITHUB_TOKEN)\n",
        "        print(\"✅ Pipeline initialized successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to initialize pipeline: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Run enhanced pipeline\n",
        "    try:\n",
        "        print(f\"\\n🏃 Starting enhanced pipeline execution...\")\n",
        "        results = pipeline.run_enhanced_pipeline(sample_size=15)  # Smaller sample for demo\n",
        "\n",
        "        if results:\n",
        "            print(f\"\\n🎊 SUCCESS! Enhanced bug classification completed!\")\n",
        "            print(\"=\" * 70)\n",
        "\n",
        "            # Show summary statistics\n",
        "            eval_results = results['evaluation_results']\n",
        "            print(f\"\\n📊 FINAL SUMMARY:\")\n",
        "            print(f\"   Overall accuracy: {eval_results['accuracy']:.3f}\")\n",
        "            print(f\"   Average confidence: {eval_results.get('avg_confidence', 0):.3f}\")\n",
        "            print(f\"   Successful predictions: {eval_results['successful_predictions']}\")\n",
        "            print(f\"   Failed predictions: {eval_results['failed_predictions']}\")\n",
        "\n",
        "            return results\n",
        "        else:\n",
        "            print(f\"❌ Pipeline execution failed\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Pipeline execution error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# File upload function for Colab\n",
        "def upload_dataset():\n",
        "    \"\"\"Upload dataset file in Google Colab\"\"\"\n",
        "    from google.colab import files\n",
        "\n",
        "    print(\"📁 Upload your bug_classification_dataset.csv file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"✅ Uploaded: {filename} ({len(uploaded[filename])} bytes)\")\n",
        "\n",
        "    # Move to expected location\n",
        "    import shutil\n",
        "    for filename in uploaded.keys():\n",
        "        if filename.endswith('.csv'):\n",
        "            shutil.move(filename, '/content/bug_classification_dataset.csv')\n",
        "            print(f\"📂 Moved {filename} to /content/bug_classification_dataset.csv\")\n",
        "            print(\"🎉 Dataset ready! You can now run main()\")\n",
        "            break\n",
        "    else:\n",
        "        print(\"⚠️ Please upload a CSV file containing your dataset\")\n",
        "\n",
        "# Demo functions\n",
        "def demo_single_classification():\n",
        "    \"\"\"Demo single issue classification\"\"\"\n",
        "    test_url = \"https://github.com/spring-projects/spring-boot/issues/29321\"\n",
        "\n",
        "    result = classify_single_issue(test_url, OPENAI_API_KEY, GITHUB_TOKEN)\n",
        "\n",
        "    if result:\n",
        "        print(\"\\n✅ Single classification demo completed!\")\n",
        "    else:\n",
        "        print(\"\\n❌ Single classification demo failed\")\n",
        "\n",
        "def demo_batch_classification():\n",
        "    \"\"\"Demo batch classification with a few URLs\"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    # Create demo CSV\n",
        "    demo_urls = [\n",
        "        \"https://github.com/elastic/elasticsearch/issues/82391\",\n",
        "        \"https://github.com/netty/netty/issues/11806\",\n",
        "        \"https://github.com/spring-projects/spring-boot/issues/29321\"\n",
        "    ]\n",
        "\n",
        "    demo_df = pd.DataFrame({'url': demo_urls})\n",
        "    demo_df.to_csv('/content/demo_issues.csv', index=False)\n",
        "\n",
        "    print(\"🧪 Running batch classification demo...\")\n",
        "    results = batch_classify_with_enhanced_features(\n",
        "        '/content/demo_issues.csv',\n",
        "        OPENAI_API_KEY,\n",
        "        GITHUB_TOKEN,\n",
        "        '/content/demo_results.csv',\n",
        "        max_issues=3\n",
        "    )\n",
        "\n",
        "    if results is not None:\n",
        "        print(\"\\n✅ Batch classification demo completed!\")\n",
        "        print(f\"Results saved to: /content/demo_results.csv\")\n",
        "        return results\n",
        "    else:\n",
        "        print(\"\\n❌ Batch classification demo failed\")"
      ],
      "metadata": {
        "id": "spjyx6iBfBhL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN THE SYSTEM"
      ],
      "metadata": {
        "id": "CGMLtlJZfkq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"🚀 ENHANCED BUG CLASSIFICATION SYSTEM - READY!\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\n📋 Available functions:\")\n",
        "    print(\"1. upload_dataset() - Upload your training dataset\")\n",
        "    print(\"2. main() - Run the complete enhanced pipeline\")\n",
        "    print(\"3. demo_single_classification() - Test single issue classification\")\n",
        "    print(\"4. demo_batch_classification() - Test batch classification\")\n",
        "    print(\"5. classify_single_issue(url, api_key, github_token) - Classify any GitHub issue\")\n",
        "    print(\"\\n💡 Start by running: upload_dataset()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YwL0XCjfNHk",
        "outputId": "4bac440c-caf5-40d6-c48d-ec2a50735579"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 ENHANCED BUG CLASSIFICATION SYSTEM - READY!\n",
            "======================================================================\n",
            "\n",
            "📋 Available functions:\n",
            "1. upload_dataset() - Upload your training dataset\n",
            "2. main() - Run the complete enhanced pipeline\n",
            "3. demo_single_classification() - Test single issue classification\n",
            "4. demo_batch_classification() - Test batch classification\n",
            "5. classify_single_issue(url, api_key, github_token) - Classify any GitHub issue\n",
            "\n",
            "💡 Start by running: upload_dataset()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "upload_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "TwflIt9QiMAI",
        "outputId": "50f99edf-e9a2-4543-c7c0-b42032942cee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Upload your bug_classification_dataset.csv file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c785baff-497f-4e9c-8227-2df04ecfc3eb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c785baff-497f-4e9c-8227-2df04ecfc3eb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bug_classification_dataset.csv to bug_classification_dataset.csv\n",
            "✅ Uploaded: bug_classification_dataset.csv (50663 bytes)\n",
            "📂 Moved bug_classification_dataset.csv to /content/bug_classification_dataset.csv\n",
            "🎉 Dataset ready! You can now run main()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaDAn0iFqkjl",
        "outputId": "f00a0e45-0d73-4bce-883c-70b48ccef7b6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 ENHANCED BUG CLASSIFICATION SYSTEM\n",
            "======================================================================\n",
            "❌ Failed to initialize pipeline: name 'Github' is not defined\n"
          ]
        }
      ]
    }
  ]
}